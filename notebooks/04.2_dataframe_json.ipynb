{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "844088d7-a23f-480e-9cf4-0896e1f0cc59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- **Name:** 001_Introduction\n",
    "- **Author:** Shamas Imran\n",
    "- **Desciption:** Read JSON from Variable and Create DataFrame \n",
    "<!--\n",
    "Version          Date        Author           Desciption\n",
    "01           19-Aug-2025   Shamas Imran       Handles simple, nested, array, and schema drift JSON \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c8759d6-03a8-4891-839d-27b0341a08db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "684b868b-4a58-4107-b277-72385236d889",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "# 1) JSON variable (array of objects, multi-line)\n",
    "json_variable = \"\"\"\n",
    "[\n",
    "  {\n",
    "    \"id\": 1,\n",
    "    \"name\": \"Alice\",\n",
    "    \"age\": 30,\n",
    "    \"address\": {\"street\": \"Main St\", \"city\": \"NY\"},\n",
    "    \"phones\": [\"123-4567\", \"987-6543\"]\n",
    "  },\n",
    "  {\n",
    "    \"id\": 2,\n",
    "    \"name\": \"Bob\",\n",
    "    \"address\": {\"street\": \"2nd St\", \"city\": \"LA\"},\n",
    "    \"phones\": [\"555-5555\"],\n",
    "    \"email\": \"bob@example.com\"\n",
    "  }\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "675310ed-d9db-4b64-9a68-98f7273b130f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2) Parse JSON string and create DataFrame\n",
    "data = json.loads(json_variable)\n",
    "df = spark.createDataFrame(data)\n",
    "\n",
    "print(\"=== Raw DataFrame ===\")\n",
    "display(df)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c9d7bd9-de1c-4ba9-baa5-8cb4718ff5cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3) Flatten nested JSON and explode arrays\n",
    "if \"phones\" in df.columns:\n",
    "    df_exploded = df.withColumn(\"phone\", explode(col(\"phones\")))\n",
    "else:\n",
    "    df_exploded = df\n",
    "\n",
    "if \"address\" in df.columns:\n",
    "    df_flat = df_exploded.select(\n",
    "        \"id\",\n",
    "        \"name\",\n",
    "        \"age\",\n",
    "        \"email\",\n",
    "        col(\"address.street\").alias(\"street\"),\n",
    "        col(\"address.city\").alias(\"city\"),\n",
    "        \"phone\"\n",
    "    )\n",
    "else:\n",
    "    df_flat = df_exploded\n",
    "\n",
    "print(\"=== Flattened DataFrame ===\")\n",
    "display(df_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c195fef-fa95-4463-b225-8061fe6ae10d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4) Handle schema drift with another JSON variable\n",
    "json_variable2 = \"\"\"\n",
    "[\n",
    "  {\n",
    "    \"id\": 3,\n",
    "    \"name\": \"Charlie\",\n",
    "    \"age\": 28,\n",
    "    \"gender\": \"M\"\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "data2 = json.loads(json_variable2)\n",
    "df2 = spark.createDataFrame(data2)\n",
    "\n",
    "df_union = df_flat.unionByName(df2, allowMissingColumns=True)\n",
    "\n",
    "print(\"=== Union with Schema Drift ===\")\n",
    "display(df_union)\n",
    "df_union.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8218812668408036,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04.2_dataframe_json",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

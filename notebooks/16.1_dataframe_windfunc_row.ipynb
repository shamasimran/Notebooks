{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1128edb6-c3ff-4a88-b9ca-04f8ced1c20a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- **Name:** 001_Introduction\n",
    "- **Author:** Shamas Imran\n",
    "- **Desciption:** Implementing aggregations using dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9ad18422-66d4-4070-a93f-fa42831c2973",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from datetime import date \n",
    "import random\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Student DataFrame\n",
    "# -------------------------------\n",
    "student_schema = StructType([\n",
    "    StructField('StudentID', IntegerType(), False),\n",
    "    StructField('StudentName', StringType(), True),\n",
    "    StructField('StudentAge', IntegerType(), True)\n",
    "])\n",
    "\n",
    "student_data = [\n",
    "    (1, \"Alice\", 34), \n",
    "    (2, \"Bob\", 45), \n",
    "    (3, \"Charlie\", 29),\n",
    "    (4, \"Shamas\", 40)\n",
    "]\n",
    "\n",
    "df_student = spark.createDataFrame(student_data, student_schema)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Course DataFrame\n",
    "# -------------------------------\n",
    "course_schema = StructType([\n",
    "    StructField('CourseID', IntegerType(), False),\n",
    "    StructField('CourseName', StringType(), True),\n",
    "    StructField('CourseTitle', StringType(), True),\n",
    "])\n",
    "\n",
    "course_data = [\n",
    "    (1, \"Physics\", \"1111\"), \n",
    "    (2, \"Chemistry\", \"2222\"), \n",
    "    (3, \"English\", \"3333\"),\n",
    "    (4, \"Computer Science\", \"4444\")\n",
    "]\n",
    "\n",
    "df_course = spark.createDataFrame(course_data, course_schema)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Enrollment DataFrame\n",
    "# -------------------------------\n",
    "enrollment_schema = StructType([\n",
    "    StructField(\"EnrollmentID\", IntegerType(), False),\n",
    "    StructField(\"StudentID_FK\", IntegerType(), False),\n",
    "    StructField(\"CourseID_FK\", IntegerType(), False),\n",
    "    StructField(\"EnrollmentDate\", DateType(), True)\n",
    "])\n",
    "\n",
    "enrollment_data = [\n",
    "    (1, 1, 1, date(2023, 9, 1)),   # Alice -> Physics\n",
    "    (2, 2, 2, date(2023, 9, 2)),   # Bob -> Chemistry\n",
    "    (3, 4, 4, date(2023, 9, 4)),   # Shamas -> Computer Science\n",
    "    (4, 1, 2, date(2023, 9, 5)),   # Alice -> Chemistry\n",
    "]\n",
    "\n",
    "df_enrollment = spark.createDataFrame(enrollment_data, enrollment_schema)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Score DataFrame\n",
    "# -------------------------------\n",
    "semesters = [\"2023-Spring\", \"2023-Fall\", \"2024-Spring\", \"2024-Fall\", \"2025-Spring\"]\n",
    "score_data = []\n",
    "score_id = 1\n",
    "enrollment_ids = [row.EnrollmentID for row in df_enrollment.collect()]\n",
    "\n",
    "for enrollment_id in enrollment_ids:\n",
    "    selected_semesters = random.sample(semesters, k=random.randint(2, 4))\n",
    "    for sem in selected_semesters:\n",
    "        score_data.append(Row(\n",
    "            ScoreID=score_id,\n",
    "            EnrollmentID_FK=enrollment_id,\n",
    "            Semester=sem,\n",
    "            Score=random.randint(60, 100)\n",
    "        ))\n",
    "        score_id += 1\n",
    "\n",
    "score_schema = StructType([\n",
    "    StructField(\"ScoreID\", IntegerType(), False),\n",
    "    StructField(\"EnrollmentID_FK\", IntegerType(), False),\n",
    "    StructField(\"Semester\", StringType(), True),\n",
    "    StructField(\"Score\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "df_score = spark.createDataFrame(score_data, schema=score_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eadea1fe-8013-432a-aaf3-87b68d126db7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define row window: partition by course, order by score\n",
    "row_window = (\n",
    "    Window.partitionBy(\"e.CourseID_FK\")\n",
    "    .orderBy(\"s.Score\")\n",
    "    .rowsBetween(-2, 2)  # 2 rows before, current row, 2 rows after\n",
    ")\n",
    "\n",
    "df_score.alias(\"s\") \\\n",
    "    .join(df_enrollment.alias(\"e\"), F.col(\"s.EnrollmentID_FK\") == F.col(\"e.EnrollmentID\")) \\\n",
    "    .withColumn(\"MovingAvg\", F.avg(\"s.Score\").over(row_window)) \\\n",
    "    .select(\"e.CourseID_FK\", \"s.Score\", \"MovingAvg\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "008b6c58-a5c1-4e02-8342-c7bffc101f62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example 1: Running average score per course\n",
    "df_score.alias(\"s\") \\\n",
    "    .join(df_enrollment.alias(\"e\"), F.col(\"s.EnrollmentID_FK\") == F.col(\"e.EnrollmentID\")) \\\n",
    "    .withColumn(\"RunningAvg\", F.avg(\"s.Score\").over(course_window)) \\\n",
    "    .select(\"e.CourseID_FK\", \"s.Score\", \"RunningAvg\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc02aa3e-7db9-4451-bb47-e56c42a7b05c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example 2: Running Total (from first row to current row)\n",
    "running_window = (\n",
    "    Window.partitionBy(\"e.CourseID_FK\")\n",
    "    .orderBy(\"s.Score\")\n",
    "    .rowsBetween(Window.unboundedPreceding, 0)  # everything up to current row\n",
    ")\n",
    "\n",
    "df_score.alias(\"s\") \\\n",
    "    .join(df_enrollment.alias(\"e\"), F.col(\"s.EnrollmentID_FK\") == F.col(\"e.EnrollmentID\")) \\\n",
    "    .withColumn(\"RunningTotal\", F.sum(\"s.Score\").over(running_window)) \\\n",
    "    .select(\"e.CourseID_FK\", \"s.Score\", \"RunningTotal\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6479c808-8937-4862-a9e9-785b5ca4edc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "forward_window = (\n",
    "    Window.partitionBy(\"e.CourseID_FK\")\n",
    "    .orderBy(\"s.Score\")\n",
    "    .rowsBetween(0, Window.unboundedFollowing)  # current row to end\n",
    ")\n",
    "\n",
    "df_score.alias(\"s\") \\\n",
    "    .join(df_enrollment.alias(\"e\"), F.col(\"s.EnrollmentID_FK\") == F.col(\"e.EnrollmentID\")) \\\n",
    "    .withColumn(\"ForwardTotal\", F.sum(\"s.Score\").over(forward_window)) \\\n",
    "    .select(\"e.CourseID_FK\", \"s.Score\", \"ForwardTotal\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "960a7b78-eada-4a59-bcec-4301e41360a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example 4: Row Difference (current row vs previous row)\n",
    "diff_window = (\n",
    "    Window.partitionBy(\"e.CourseID_FK\")\n",
    "    .orderBy(\"s.Score\")\n",
    "    .rowsBetween(-1, 0)  # previous row + current row\n",
    ")\n",
    "\n",
    "df_score.alias(\"s\") \\\n",
    "    .join(df_enrollment.alias(\"e\"), F.col(\"s.EnrollmentID_FK\") == F.col(\"e.EnrollmentID\")) \\\n",
    "    .withColumn(\"RowDiff\", (F.sum(\"s.Score\").over(diff_window) - F.col(\"s.Score\"))) \\\n",
    "    .select(\"e.CourseID_FK\", \"s.Score\", \"RowDiff\") \\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3223090135813926,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "16.1_dataframe_windfunc_row",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

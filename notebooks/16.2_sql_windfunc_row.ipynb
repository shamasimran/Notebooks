{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1128edb6-c3ff-4a88-b9ca-04f8ced1c20a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- **Name:** 001_Introduction\n",
    "- **Author:** Shamas Imran\n",
    "- **Desciption:** Implementing aggregations using dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9ad18422-66d4-4070-a93f-fa42831c2973",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from datetime import date \n",
    "import random\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Student DataFrame\n",
    "# -------------------------------\n",
    "student_schema = StructType([\n",
    "    StructField('StudentID', IntegerType(), False),\n",
    "    StructField('StudentName', StringType(), True),\n",
    "    StructField('StudentAge', IntegerType(), True)\n",
    "])\n",
    "\n",
    "student_data = [\n",
    "    (1, \"Alice\", 34), \n",
    "    (2, \"Bob\", 45), \n",
    "    (3, \"Charlie\", 29),\n",
    "    (4, \"Shamas\", 40)\n",
    "]\n",
    "\n",
    "df_student = spark.createDataFrame(student_data, student_schema)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Course DataFrame\n",
    "# -------------------------------\n",
    "course_schema = StructType([\n",
    "    StructField('CourseID', IntegerType(), False),\n",
    "    StructField('CourseName', StringType(), True),\n",
    "    StructField('CourseTitle', StringType(), True),\n",
    "])\n",
    "\n",
    "course_data = [\n",
    "    (1, \"Physics\", \"1111\"), \n",
    "    (2, \"Chemistry\", \"2222\"), \n",
    "    (3, \"English\", \"3333\"),\n",
    "    (4, \"Computer Science\", \"4444\")\n",
    "]\n",
    "\n",
    "df_course = spark.createDataFrame(course_data, course_schema)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Enrollment DataFrame\n",
    "# -------------------------------\n",
    "enrollment_schema = StructType([\n",
    "    StructField(\"EnrollmentID\", IntegerType(), False),\n",
    "    StructField(\"StudentID_FK\", IntegerType(), False),\n",
    "    StructField(\"CourseID_FK\", IntegerType(), False),\n",
    "    StructField(\"EnrollmentDate\", DateType(), True)\n",
    "])\n",
    "\n",
    "enrollment_data = [\n",
    "    (1, 1, 1, date(2023, 9, 1)),   # Alice -> Physics\n",
    "    (2, 2, 2, date(2023, 9, 2)),   # Bob -> Chemistry\n",
    "    (3, 4, 4, date(2023, 9, 4)),   # Shamas -> Computer Science\n",
    "    (4, 1, 2, date(2023, 9, 5)),   # Alice -> Chemistry\n",
    "]\n",
    "\n",
    "df_enrollment = spark.createDataFrame(enrollment_data, enrollment_schema)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Score DataFrame\n",
    "# -------------------------------\n",
    "semesters = [\"2023-Spring\", \"2023-Fall\", \"2024-Spring\", \"2024-Fall\", \"2025-Spring\"]\n",
    "score_data = []\n",
    "score_id = 1\n",
    "enrollment_ids = [row.EnrollmentID for row in df_enrollment.collect()]\n",
    "\n",
    "for enrollment_id in enrollment_ids:\n",
    "    selected_semesters = random.sample(semesters, k=random.randint(2, 4))\n",
    "    for sem in selected_semesters:\n",
    "        score_data.append(Row(\n",
    "            ScoreID=score_id,\n",
    "            EnrollmentID_FK=enrollment_id,\n",
    "            Semester=sem,\n",
    "            Score=random.randint(60, 100)\n",
    "        ))\n",
    "        score_id += 1\n",
    "\n",
    "score_schema = StructType([\n",
    "    StructField(\"ScoreID\", IntegerType(), False),\n",
    "    StructField(\"EnrollmentID_FK\", IntegerType(), False),\n",
    "    StructField(\"Semester\", StringType(), True),\n",
    "    StructField(\"Score\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "df_score = spark.createDataFrame(score_data, schema=score_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cba5be0c-e5cb-44a3-bea5-2520bbd7c5d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_student.createOrReplaceTempView(\"Student\")\n",
    "df_course.createOrReplaceTempView(\"Course\")\n",
    "df_enrollment.createOrReplaceTempView(\"Enrollment\")\n",
    "df_score.createOrReplaceTempView(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eadea1fe-8013-432a-aaf3-87b68d126db7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Example: Moving average of scores within a window of 2 rows before and 2 rows after\n",
    "SELECT\n",
    "    e.CourseID_FK,\n",
    "    s.Score,\n",
    "    AVG(s.Score) OVER (\n",
    "        PARTITION BY e.CourseID_FK    -- partition by course\n",
    "        ORDER BY s.Score              -- order scores\n",
    "        ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING  -- sliding window of 5 rows (2 before, current, 2 after)\n",
    "    ) AS MovingAvg\n",
    "FROM Score s\n",
    "JOIN Enrollment e\n",
    "    ON s.EnrollmentID_FK = e.EnrollmentID;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "008b6c58-a5c1-4e02-8342-c7bffc101f62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Example 1: Running average score per course\n",
    "SELECT\n",
    "    e.CourseID_FK,\n",
    "    s.Score,\n",
    "    AVG(s.Score) OVER (\n",
    "        PARTITION BY e.CourseID_FK\n",
    "        ORDER BY s.Score\n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "    ) AS RunningAvg\n",
    "FROM score s\n",
    "JOIN enrollment e\n",
    "    ON s.EnrollmentID_FK = e.EnrollmentID;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc02aa3e-7db9-4451-bb47-e56c42a7b05c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Example 2: Running Total (from first row to current row)\n",
    "SELECT\n",
    "    e.CourseID_FK,\n",
    "    s.Score,\n",
    "    SUM(s.Score) OVER (\n",
    "        PARTITION BY e.CourseID_FK\n",
    "        ORDER BY s.Score\n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "    ) AS RunningTotal\n",
    "FROM Score s\n",
    "JOIN Enrollment e\n",
    "    ON s.EnrollmentID_FK = e.EnrollmentID;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6479c808-8937-4862-a9e9-785b5ca4edc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Forward running total (from current row to last row in the partition)\n",
    "SELECT\n",
    "    e.CourseID_FK,\n",
    "    s.Score,\n",
    "    SUM(s.Score) OVER (\n",
    "        PARTITION BY e.CourseID_FK\n",
    "        ORDER BY s.Score\n",
    "        ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING\n",
    "    ) AS ForwardTotal\n",
    "FROM Score s\n",
    "JOIN Enrollment e\n",
    "    ON s.EnrollmentID_FK = e.EnrollmentID;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "960a7b78-eada-4a59-bcec-4301e41360a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Row Difference: Current row vs Previous row\n",
    "SELECT\n",
    "    e.CourseID_FK,\n",
    "    s.Score,\n",
    "    s.Score - LAG(s.Score, 1) OVER (\n",
    "        PARTITION BY e.CourseID_FK\n",
    "        ORDER BY s.Score\n",
    "    ) AS RowDiff\n",
    "FROM Score s\n",
    "JOIN Enrollment e\n",
    "    ON s.EnrollmentID_FK = e.EnrollmentID;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2098735267820318,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "16.2_sql_windfunc_row",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
